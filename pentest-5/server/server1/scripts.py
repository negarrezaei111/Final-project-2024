import json
import requests
from django.contrib.auth import get_user_model
from django.utils import timezone
from .models import Scan, SubScan, VulnerabilityDetail
from .utils import check_sql_injection, check_xss, validate_url, assign_severity
from django.db import transaction
from .crawler import crawl
import logging

User = get_user_model()

logger = logging.getLogger(__name__)


def start_scan(url, user, scan_mode, main_url=None, scan_identifier=None, scan_type='all_vulnerabilities'):
    try:
        if not validate_url(url):
            raise ValueError("Invalid URL")
        print("scan mode in scripts: %s", scan_mode)

        use_deep_scan = scan_mode == 'deep'
        print("use scan mode in scripts: %s", use_deep_scan)

        scan, created = Scan.objects.get_or_create(
            user=user,
            url=url,
            defaults={ 'scan_identifier': scan_identifier, 'main_url': main_url}
        )

        if not created and not scan.can_rescan():
            return scan



        scan.status = 'in_progress'
        scan.save()

        scan_results = []
        crawled_urls = crawl(url, scan.id, scan_mode)

        with transaction.atomic():
            scan.last_scan_date = timezone.now()
            scan.save()

            for crawled_url in crawled_urls:
                scan.refresh_from_db()
                if should_stop_scan(scan):
                    scan.status = 'failed'
                    scan.save()
                    print("Scan was stopped.")
                    break

                if crawled_url == url:
                    continue

                subscan_results = []
                if scan_type in ['sql_injection', 'all_vulnerabilities']:
                    subscan_results.extend(check_sql_injection(crawled_url, use_deep_scan=use_deep_scan))
                if scan_type in ['xss', 'all_vulnerabilities']:
                    subscan_results.extend(check_xss(crawled_url, use_deep_scan=use_deep_scan))

                for result in subscan_results:
                    result['vuln_type'] = assign_severity(result.get('type', 'Unknown'))

                sub_scan = SubScan.objects.create(
                    scan=scan,
                    crawled_url=crawled_url,
                    is_vulnerable=bool(subscan_results),
                    vulnerabilities=json.dumps(subscan_results),
                    security_score=calculate_security_score(subscan_results),
                    depth=0
                )

                for result in subscan_results:
                    VulnerabilityDetail.objects.create(
                        sub_scan=sub_scan,
                        parameter=result.get('parameter', 'N/A'),
                        payload=result.get('payload', 'N/A'),
                        description=result.get('description', 'No description available'),
                        vuln_type=result.get('vuln_type', 'Unknown')
                    )
                scan_results.extend(subscan_results)
                scan.refresh_from_db()
                if should_stop_scan(scan):
                    scan.status = 'failed'
                    scan.save()
                    print("Scan was stopped.")
                    break

            scan.is_vulnerable = bool(scan_results)
            scan.vulnerabilities = json.dumps(scan_results)
            scan.security_score = calculate_security_score(scan_results)
            scan.status = 'completed'
            scan.save()

            return scan

    except requests.exceptions.RequestException as e:
        logger.error("RequestException during scan: %s", e)
        raise

    except ValueError as ve:
        logger.error("ValueError during scan: %s", ve)
        raise


def should_stop_scan(scan):
    scan.refresh_from_db()
    return scan.is_stopping or scan.status in ['failed', 'completed']


def stop_scan_process(scan_identifier=None):
    try:
        print("Stopping scans with identifier: %s", scan_identifier)
        scans = Scan.objects.filter(scan_identifier=scan_identifier).select_for_update()

        if not scans.exists():
            print("No scans found with identifier %s.", scan_identifier)
            return False

        for scan in scans:
            if scan.status in ['completed', 'failed']:
                print("Scan with ID %d is already %s.", scan.id, scan.status)
                continue
            scan.is_stopping = True
            scan.status = 'failed'
            scan.save()
            print("Scan with ID %d status updated to 'failed'.", scan.id)

        delete_sub_scans_and_vulnerabilities(scans)

        return True

    except Exception as e:
        logger.error("Error stopping scan process: %s", e)
        return False


def delete_sub_scans_and_vulnerabilities(scans):
    try:
        with transaction.atomic():
            for scan in scans:
                sub_scans = SubScan.objects.filter(scan=scan)
                sub_scan_ids = sub_scans.values_list('id', flat=True)
                VulnerabilityDetail.objects.filter(sub_scan__in=sub_scan_ids).delete()
                sub_scans.delete()
                print("Sub-scans and vulnerability details deleted for scan ID %d.", scan.id)

    except Exception as e:
        logger.error("Error deleting sub-scans: %s", e)


def continue_scan_process(scan_identifier, scan_mode):
    try:
        scans = Scan.objects.filter(scan_identifier=scan_identifier, status='failed')

        if not scans.exists():
            print("No failed scans found with identifier %s.", scan_identifier)
            return False

        with transaction.atomic():
            for scan in scans:
                scan.status = 'in_progress'
                delete_sub_scans_and_vulnerabilities(scans)
                scan.is_stopping = False
                scan.save()
                print("Scan with ID %d status updated to 'in_progress'.", scan.id)

                failed_subscans = SubScan.objects.filter(scan=scan, is_vulnerable=False)

                crawled_urls = crawl(scan.url, scan.id, scan_mode)
                existing_urls = set(failed_subscans.values_list('crawled_url', flat=True))

                for crawled_url in crawled_urls:

                    scan.refresh_from_db()
                    if scan.is_stopping:
                        scan.status = 'failed'
                        scan.save()
                        print("Scan with ID %d was stopped during continue.", scan.id)
                        return False

                    if crawled_url in existing_urls:
                        SubScan.objects.filter(scan=scan, crawled_url=crawled_url).delete()
                        print("Deleted failed SubScan for %s.", crawled_url)

                    sub_scan = SubScan.objects.create(
                        scan=scan,
                        crawled_url=crawled_url,
                        is_vulnerable=False,
                        vulnerabilities="[]",
                        security_score=100,
                        depth=0
                    )

                    scan_results = []
                    if scan.scan_type in ['sql_injection', 'all_vulnerabilities']:
                        scan_results.extend(check_sql_injection(crawled_url))
                    if scan.scan_type in ['xss', 'all_vulnerabilities']:
                        scan_results.extend(check_xss(crawled_url))

                    sub_scan.vulnerabilities = json.dumps(scan_results)
                    sub_scan.is_vulnerable = bool(scan_results)
                    sub_scan.security_score = calculate_security_score(scan_results)
                    sub_scan.save()

                    VulnerabilityDetail.objects.filter(sub_scan=sub_scan).delete()
                    for result in scan_results:
                        VulnerabilityDetail.objects.create(
                            sub_scan=sub_scan,
                            parameter=result.get('parameter', 'N/A'),
                            payload=result.get('payload', 'N/A'),
                            description=result.get('description', 'No description available'),
                            vuln_type=result.get('vuln_type', 'Unknown')
                        )

                subscans = SubScan.objects.filter(scan=scan)
                scan.is_vulnerable = any(sub_scan.is_vulnerable for sub_scan in subscans)

                all_vulnerabilities = []
                for sub_scan in subscans:
                    vulnerabilities = json.loads(sub_scan.vulnerabilities)
                    all_vulnerabilities.extend(vulnerabilities)

                scan.vulnerabilities = json.dumps(all_vulnerabilities)
                scan.security_score = calculate_security_score(all_vulnerabilities)
                scan.status = 'completed'
                scan.save()

        return True

    except Exception as e:
        logger.error("Error continuing scan process: %s", e)
        return False


def calculate_security_score(vulnerabilities):
    if not vulnerabilities:
        return 100

    score = 100
    sql_injection_weight = 10
    xss_weight = 5

    for vuln in vulnerabilities:
        description = vuln.get('description', '').lower()
        if 'sql' in description:
            score -= sql_injection_weight
        elif 'xss' in description:
            score -= xss_weight

    return max(score, 0)


def get_scan_results(scan_id):
    try:
        scan = Scan.objects.get(id=scan_id)
        subscans = SubScan.objects.filter(scan=scan)

        results = {
            'scan': {
                'id': scan.id,
                'url': scan.url,
                'scan_date': scan.scan_date,
                'is_vulnerable': scan.is_vulnerable,
                'security_score': scan.security_score,
                'vulnerabilities': scan.vulnerabilities,
                'status': scan.status
            },
            'subscans': [
                {
                    'crawled_url': subscan.crawled_url,
                    'is_vulnerable': subscan.is_vulnerable,
                    'security_score': subscan.security_score,
                    'vulnerabilities': json.loads(subscan.vulnerabilities),
                    'depth': subscan.depth
                } for subscan in subscans
            ]
        }
        return results

    except Scan.DoesNotExist:
        print(f"Scan with id {scan_id} does not exist.")
        return None

    except Exception as e:
        import traceback
        print(f"Error retrieving scan results: {traceback.format_exc()}")
        raise
